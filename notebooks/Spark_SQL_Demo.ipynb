{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Traffic Patterns to Wikimedia Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.log4j._\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data dump is taken from Wikimedia site : https://dumps.wikimedia.org/other/pageviews/2017/\n",
    "\n",
    "* It holds daily consolidated traffic data based on the article requests.\n",
    "\n",
    "* Data is found is space separated colums in human readable format\n",
    "\n",
    "`\n",
    "Note: preprocessing is done to filter out only EN articles and saved them in parquet format\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task for Data Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [project: string, article: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val df = spark.read.parquet(\"/Users/josiahsams/SparkDemo/datasets/parquet/pageviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project: string (nullable = true)\n",
      " |-- article: string (nullable = true)\n",
      " |-- requests: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         requests|\n",
      "+-------+-----------------+\n",
      "|  count|          2095763|\n",
      "|   mean|4.252991869786803|\n",
      "| stddev|659.0505003693299|\n",
      "|    min|                1|\n",
      "|    max|           948323|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Int = 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|project|             article|requests|\n",
      "+-------+--------------------+--------+\n",
      "|     en|                 !!!|       4|\n",
      "|     en|       !Ora_language|       1|\n",
      "|     en|    \"A\"_Is_for_Alibi|       1|\n",
      "|     en|    Awaken,_My_Love!|      14|\n",
      "|     en|\"C\"_Is_for_(Pleas...|       2|\n",
      "|     en|   Come_On,_Let's_Go|       1|\n",
      "|     en|  \"Dear_Boss\"_letter|       1|\n",
      "|     en|  \"G\"_Is_for_Gumshoe|       1|\n",
      "|     en|              Heroes|       1|\n",
      "|     en|       \"I_want\"_song|       1|\n",
      "|     en|   \"M\"_Is_for_Malice|       1|\n",
      "|     en|\"Panzer_ace\"_in_p...|       1|\n",
      "|     en| \"R\"_Is_for_Ricochet|       1|\n",
      "|     en|     \"Sin\"_Blackwood|       1|\n",
      "|     en|\"This_Is_Our_Punk...|       1|\n",
      "|     en|          \"V\"_device|      29|\n",
      "|     en|\"Weird_Al\"_Yankov...|      12|\n",
      "|     en|  \"Wild_Bill\"_Hickok|       9|\n",
      "|     en|                   $|       1|\n",
      "|     en|               $1000|       1|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down different type of projects available in EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|  project|  count|\n",
      "+---------+-------+\n",
      "|       en|1185441|\n",
      "|     en.m| 783366|\n",
      "|  en.zero|  51727|\n",
      "|     en.d|  36218|\n",
      "|   en.m.d|  19915|\n",
      "|     en.b|   4472|\n",
      "|     en.q|   2712|\n",
      "|   en.m.b|   2669|\n",
      "|     en.s|   1873|\n",
      "|   en.m.q|   1771|\n",
      "|   en.voy|   1295|\n",
      "|     en.v|    988|\n",
      "|   en.m.s|    912|\n",
      "|en.zero.d|    512|\n",
      "| en.m.voy|    510|\n",
      "|   en.m.v|    400|\n",
      "|     en.n|    362|\n",
      "|en.zero.b|    274|\n",
      "|   en.m.n|     99|\n",
      "|en.zero.q|     83|\n",
      "+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"project\").count().orderBy(col(\"count\").desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out only EN wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filterEN: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [project: string, article: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val filterEN = df.filter(col(\"project\") === \"en\").cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top Articles based on the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|project|             article|requests|\n",
      "+-------+--------------------+--------+\n",
      "|     en|           Main_Page|  948323|\n",
      "|     en|      Special:Search|   48502|\n",
      "|     en|                   -|    7662|\n",
      "|     en|List_of_macOS_com...|    6561|\n",
      "|     en|Star_Trek:_Discovery|    4974|\n",
      "|     en|        Special:Book|    4464|\n",
      "|     en|German_federal_el...|    3818|\n",
      "|     en|         Darth_Vader|    3749|\n",
      "|     en|  Special:LinkSearch|    3125|\n",
      "|     en|Alternative_for_G...|    3040|\n",
      "|     en|      Deaths_in_2017|    2453|\n",
      "|     en|        Frauke_Petry|    2249|\n",
      "|     en|     No_Mercy_(2017)|    2208|\n",
      "|     en|Catherine_Zeta-Jones|    2096|\n",
      "|     en|   Special:Watchlist|    2040|\n",
      "|     en| Special:ElectronPdf|    2028|\n",
      "|     en|       Howard_Hughes|    1899|\n",
      "|     en|               Earth|    1847|\n",
      "|     en|Kingsman:_The_Gol...|    1750|\n",
      "|     en|      It_(2017_film)|    1705|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterEN.orderBy(col(\"requests\").desc).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filterDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [project: string, article: string ... 1 more field]\n",
       "cachedDF: filterDF.type = [project: string, article: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val filterDF = filterEN\n",
    "  .filter(col(\"article\").rlike(\"\"\"^(?!-)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Special:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!File:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Category:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!User:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Talk:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Template:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Help:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Wikipedia:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!MediaWiki:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Portal:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Book:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Draft:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Education_Program:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!TimedText:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Module:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Topic:)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!Images/)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!%22//upload.wikimedia.org)+)\"\"\"))\n",
    "  .filter(col(\"article\").rlike(\"\"\"^((?!%22//en.wikipedia.org)+)\"\"\"))\n",
    "val cachedDF = filterDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             article|requests|\n",
      "+--------------------+--------+\n",
      "|           Main_Page|  948323|\n",
      "|List_of_macOS_com...|    6561|\n",
      "|Star_Trek:_Discovery|    4974|\n",
      "|German_federal_el...|    3818|\n",
      "|         Darth_Vader|    3749|\n",
      "|Alternative_for_G...|    3040|\n",
      "|      Deaths_in_2017|    2453|\n",
      "|        Frauke_Petry|    2249|\n",
      "|     No_Mercy_(2017)|    2208|\n",
      "|Catherine_Zeta-Jones|    2096|\n",
      "|       Howard_Hughes|    1899|\n",
      "|               Earth|    1847|\n",
      "|Kingsman:_The_Gol...|    1750|\n",
      "|      It_(2017_film)|    1705|\n",
      "|Rick_and_Morty_(s...|    1622|\n",
      "|          Forum_spam|    1516|\n",
      "|            Al-Batin|    1433|\n",
      "|    Colin_Kaepernick|    1401|\n",
      "|        Alice_Weidel|    1266|\n",
      "|        September_25|    1194|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cachedDF.orderBy(col(\"requests\").desc).select(\"article\", \"requests\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many requests did the \"Apache Spark\" article recieve during this hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|requests|\n",
      "+--------+\n",
      "|      53|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cachedDF.filter(col(\"article\") === \"Apache_Spark\").select(\"requests\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Apache project received the most requests during this hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             article|requests|\n",
      "+--------------------+--------+\n",
      "|       Apache_Tomcat|     131|\n",
      "|       Apache_Hadoop|     100|\n",
      "|   Apache_OpenOffice|      85|\n",
      "|  Apache_HTTP_Server|      54|\n",
      "|        Apache_Spark|      53|\n",
      "|        Apache_Kafka|      45|\n",
      "|    Apache_Cassandra|      43|\n",
      "|      Apache_Parquet|      30|\n",
      "|      Apache_License|      29|\n",
      "|        Apache_Maven|      29|\n",
      "|     Apache_Struts_2|      26|\n",
      "|   Apache_Subversion|      23|\n",
      "|      Apache_Cordova|      23|\n",
      "|         Apache_Hive|      20|\n",
      "|         Apache_Solr|      17|\n",
      "|        Apache_Mesos|      17|\n",
      "|Apache_Software_F...|      17|\n",
      "|    Apache_ZooKeeper|      16|\n",
      "|          Apache_Ant|      15|\n",
      "|        Apache_HBase|      13|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cachedDF.filter($\"article\".startsWith(\"Apache_\"))\n",
    "     .select(\"article\", \"requests\")\n",
    "     .orderBy(col(\"requests\").desc)\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More SQL Queries: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sqlContext.setConf(\"spark.sql.shuffle.partitions\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pageviewsDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [timestamp: timestamp, site: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val pageviewsDF = spark.read.parquet(\"/Users/josiahsams/SparkDemo/datasets/repart-pageviews-by-second-tsv.parquet\").cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- site: string (nullable = true)\n",
      " |-- requests: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageviewsDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------+\n",
      "|           timestamp|   site|requests|\n",
      "+--------------------+-------+--------+\n",
      "|2015-03-16 02:20:...|desktop|    2350|\n",
      "|2015-03-16 04:55:...|desktop|    2211|\n",
      "|2015-03-16 07:47:...| mobile|     878|\n",
      "|2015-03-16 10:39:...|desktop|    2391|\n",
      "|2015-03-16 13:39:...|desktop|    2943|\n",
      "|2015-03-16 16:01:...| mobile|    1438|\n",
      "|2015-03-16 18:49:...|desktop|    3239|\n",
      "|2015-03-16 22:08:...|desktop|    2476|\n",
      "|2015-03-16 00:31:...| mobile|    1586|\n",
      "|2015-03-16 03:46:...| mobile|    1535|\n",
      "|2015-03-16 06:46:...| mobile|     959|\n",
      "|2015-03-16 09:49:...| mobile|     943|\n",
      "|2015-03-16 12:32:...| mobile|    1028|\n",
      "|2015-03-16 15:03:...| mobile|    1298|\n",
      "|2015-03-16 17:48:...|desktop|    3235|\n",
      "|2015-03-16 20:36:...| mobile|    1430|\n",
      "|2015-03-16 22:58:...| mobile|    1402|\n",
      "|2015-03-16 01:26:...|desktop|    2427|\n",
      "|2015-03-16 04:01:...| mobile|    1480|\n",
      "|2015-03-16 06:52:...|desktop|    2191|\n",
      "+--------------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageviewsDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the requests coming from mobile to Wikimedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sum(requests)|\n",
      "+-------------+\n",
      "|   4605793167|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageviewsDF.filter($\"site\" === \"mobile\")\n",
    "    .select(sum($\"requests\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the months on which this dataset is collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Months|\n",
      "+------+\n",
      "|     3|\n",
      "|     4|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageviewsDF.select(month($\"timestamp\").alias(\"Months\")).distinct().show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions like min, max, avg [more](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$) .. can also be used  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which day of the week gets most traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unorderedList: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Day_of_Week: string, sum(requests): bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|Day_of_Week|sum(requests)|\n",
      "+-----------+-------------+\n",
      "|        Tue|   1995034884|\n",
      "|        Thu|   1931508977|\n",
      "|        Sun|   1576726066|\n",
      "|        Mon|   2356809353|\n",
      "|        Wed|   1977615396|\n",
      "|        Fri|   1842512718|\n",
      "|        Sat|   1662762048|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val unorderedList = pageviewsDF.groupBy(date_format($\"timestamp\", \"E\").alias(\"Day_of_Week\"))\n",
    "            .sum().cache\n",
    "unorderedList.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderByReq: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Day_of_Week: string, sum(requests): bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|Day_of_Week|sum(requests)|\n",
      "+-----------+-------------+\n",
      "|        Mon|   2356809353|\n",
      "|        Tue|   1995034884|\n",
      "|        Wed|   1977615396|\n",
      "|        Thu|   1931508977|\n",
      "|        Fri|   1842512718|\n",
      "|        Sat|   1662762048|\n",
      "|        Sun|   1576726066|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val orderByReq = unorderedList.orderBy($\"sum(requests)\".desc)\n",
    "orderByReq.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prependNumberToDay: (day: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prependNumberToDay(day: String) = {\n",
    "    day match {\n",
    "        case \"Sun\" => \"1-Sun\"\n",
    "        case \"Mon\" => \"2-Mon\"\n",
    "        case \"Tue\" => \"3-Tue\"\n",
    "        case \"Wed\" => \"4-Wed\"\n",
    "        case \"Thu\" => \"5-Thu\"\n",
    "        case \"Fri\" => \"6-Fri\"\n",
    "        case \"Sat\" => \"7-Sat\"\n",
    "        case _ => \"UNKNOWN\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prependNumUDF: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val prependNumUDF = spark.sqlContext.udf.register(\"prependNum\", (s: String) => prependNumberToDay(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|  Day|sum(requests)|\n",
      "+-----+-------------+\n",
      "|2-Mon|   2356809353|\n",
      "|3-Tue|   1995034884|\n",
      "|4-Wed|   1977615396|\n",
      "|5-Thu|   1931508977|\n",
      "|6-Fri|   1842512718|\n",
      "|7-Sat|   1662762048|\n",
      "|1-Sun|   1576726066|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderByReq.select(prependNumUDF($\"Day_of_Week\").alias(\"Day\"), $\"sum(requests)\" ).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res23: org.apache.toree.magic.MagicOutput = MagicOutput(List())\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available line magics:\n",
      "%lsmagic %showtypes %adddeps %truncation %addjar\n",
      "\n",
      "Available cell magics:\n",
      "%%sql %%html %%javascript %%dataframe %%pyspark %%scala %%sparkr\n",
      "\n",
      "Type %<magic_name> for usage info.\n",
      "         \n"
     ]
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pageviewsDF.createOrReplaceTempView(\"pageViewTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the requests coming from mobile to Wikimedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res30: org.apache.toree.magic.MagicOutput = MagicOutput(List())\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will not be printed\n"
     ]
    }
   ],
   "source": [
    "%ShowTypes off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res31: org.apache.toree.magic.MagicOutput =\n",
       "MagicOutput(ArrayBuffer((text/plain,+-------------+\n",
       "|sum(requests)|\n",
       "+-------------+\n",
       "|   4605793167|\n",
       "+-------------+\n",
       ")))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql select sum(requests) from pageViewTable where site = \"mobile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res42: org.apache.toree.magic.MagicOutput =\n",
       "MagicOutput(ArrayBuffer((text/plain,+---------+---------+-------+\n",
       "| col_name|data_type|comment|\n",
       "+---------+---------+-------+\n",
       "|timestamp|timestamp|   null|\n",
       "|     site|   string|   null|\n",
       "| requests|      int|   null|\n",
       "+---------+---------+-------+\n",
       ")))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql \n",
    "desc pageViewTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
